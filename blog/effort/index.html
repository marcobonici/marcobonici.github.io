<!doctype html> <!-- Minimal Mistakes Jekyll Theme 4.16.4 by Michael Rose Copyright 2013-2019 Michael Rose - mademistakes.com | @mmistakes Free for personal and commercial use under the MIT license https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE --> <html lang=en > <meta charset=UTF-8 > <meta name=viewport  content="width=device-width, initial-scale=1"> <link rel=stylesheet  href="/libs/katex/katex.min.css"> <link rel=stylesheet  href="/libs/highlight/github.min.css"> <link rel=stylesheet  href="/css/franklin.css"> <link rel=stylesheet  href="/css/minimal-mistakes.css"> <link rel=stylesheet  href="/css/adjust.css"> <link rel=icon  href="/assets/temp_fav.png"> <!--[if IE ]> <style> /* old IE unsupported flexbox fixes */ .greedy-nav .site-title { padding-right: 3em; } .greedy-nav button { position: absolute; top: 0; right: 0; height: 100%; } </style> <![endif]--> <title>Effort.jl</title> <meta name=google-site-verification  content=83wzCvn1Z2WBAj5oNN1RlvnWS5Xb5MmekUS2wgld9sg  /> <body class=layout--single > <div class=masthead > <div class=masthead__inner-wrap > <div class=masthead__menu > <nav id=site-nav  class=greedy-nav > <a class=site-title  href="/">Marco Bonici</a> <ul class=visible-links > <li class=masthead__menu-item ><a href="/blog/" >Blog</a> <li class=masthead__menu-item ><a href="/work/" >Publications</a> <li class=masthead__menu-item ><a href="/Bonici_CV.pdf" >CV</a> <li class=masthead__menu-item ><a href="/hobbies/">Other Interests</a> </ul> <button class="greedy-nav__toggle hidden" type=button > <span class=visually-hidden >Toggle menu</span> <div class=navicon ></div> </button> <ul class="hidden-links hidden"></ul> </nav> </div> </div> </div> <div class=initial-content > <div id=main  role=main > <div class="sidebar sticky"> <div itemscope itemtype="https://schema.org/Person"> <div class=author__avatar > <img src="/assets/portrait.jpg" alt=Me  itemprop=image > </div> <div class=author__content > <h3 class=author__name  itemprop=name >Marco Bonici</h3> <p class=author__bio  itemprop=description >PostDoctoral Researcher at Waterloo Center for Astrophysics. Cosmologist working in the field of the large-scale-structure of the Universe. JuliaLang enthusiast.</p> </div> <div class=author__urls-wrapper > <button class="btn btn--inverse">Follow</button> <ul class="author__urls social-icons"> <li itemprop=homeLocation  itemscope itemtype="https://schema.org/Place"> <i class="fas fa-fw fa-map-marker-alt" aria-hidden=true ></i> <span itemprop=name >Waterloo, Canada</span> <li><a href="https://twitter.com/marcobonici" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-twitter-square" aria-hidden=true ></i> Twitter</a> <li><a href="https://mathstodon.xyz/@marcobonici" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-mastodon" aria-hidden=true ></i> Mastodon</a> <li><a href="https://github.com/marcobonici" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-github" aria-hidden=true ></i> GitHub</a> <li><a href="mailto:mbonici@uwaterloo.ca" rel="nofollow noopener noreferrer"><i class="fa fa-envelope" aria-hidden=true ></i> Email</a> </ul> </div> </div> </div> <script src="/libs/clipboard.min.js"></script><div class=franklin-content ><h1 id=the_julia_eftoflss_emulator_here_comes_effort ><a href="#the_julia_eftoflss_emulator_here_comes_effort" class=header-anchor >The Julia EFTofLSS emulator: here comes Effort&#33;</a></h1> <p>One of the recent hot topics in cosmology is the development of emulators, surrogate models designed to approximate computationally expensive functions with far more efficient alternatives. While many advancements have focused on emulating Cosmic Microwave Background &#40;CMB&#41; calculations, such as ClassNet<sup id="fnref:classnet"><a href="#fndef:classnet" class=fnref >[1]</a></sup> and Cosmopower<sup id="fnref:cosmopower"><a href="#fndef:cosmopower" class=fnref >[2]</a></sup>, the spotlight has recently shifted to emulators for Large-Scale Structure &#40;LSS&#41; analyses, after the release of new analyses from the DESI collaboration.</p> <p><code>Effort.jl</code> focuses on emulating the galaxy power spectrum in the context of the Effective Field Theory of Large-Scale Structure &#40;EFTofLSS&#41;, a cornerstone framework for interpreting LSS surveys. But why yet another emulator? What makes <code>Effort.jl</code> stand out from the many existing tools?</p> <p>While other frameworks such as EmulateLSS<sup id="fnref:emulatelss"><a href="#fndef:emulatelss" class=fnref >[3]</a></sup>, Matryoshka<sup id="fnref:matryoshka"><a href="#fndef:matryoshka" class=fnref >[4]</a></sup>, COMET<sup id="fnref:comet"><a href="#fndef:comet" class=fnref >[5]</a></sup>, COBRA<sup id="fnref:cobra"><a href="#fndef:cobra" class=fnref >[6]</a></sup>, and Pybird-JAX<sup id="fnref:pybird"><a href="#fndef:pybird" class=fnref >[7]</a></sup> have laid the groundwork, <code>Effort.jl</code> aims to take the game a step further, with a focus on computational efficiency and flexibility. Hereâ€™s how:</p> <p>âš¡ Blazing Performance: <code>Effort.jl</code> can compute the galaxy power spectrum multipoles in approximately 15 Âµsâ€”orders of magnitude faster than traditional Boltzmann solvers. This is thanks to its integration with the high-performance <code>Julia</code> ecosystem.</p> <p>ðŸ§  Physics-Based Preprocessing: To reduce training resources, <code>Effort.jl</code> incorporates analytical rescaling of input and output features based on the underlying physics of the problem. This preprocessing minimizes the emulatorâ€™s complexity while maintaining precision.</p> <p>ðŸ”‹ Effortless<sup id="fnref:pun"><a href="#fndef:pun" class=fnref >[8]</a></sup> Training: Unlike many resource-heavy frameworks, <code>Effort.jl</code> is designed to be trained efficiently using standard hardware, completing training in about one hour on a standard CPU.</p> <p>ðŸŽ¯ Gradient-Based Optimization: <code>Effort.jl</code> is fully differentiable, enabling seamless integration with gradient-based algorithms for Bayesian inference and parameter minimization. This opens up possibilities for faster and more accurate cosmological analyses.</p> <p>These characteristics make <code>Effort.jl</code> an appealing choice for cosmologists working on next-generation surveys, such as DESI and Euclid, where precision and computational efficiency are paramount; for this reason, <code>Effort.jl</code> has already been applied in a few works<sup id="fnref:zhangone"><a href="#fndef:zhangone" class=fnref >[9]</a></sup><sup id="fnref:paradiso"><a href="#fndef:paradiso" class=fnref >[10]</a></sup><sup id="fnref:baleato"><a href="#fndef:baleato" class=fnref >[11]</a></sup><sup id="fnref:zhangtwo"><a href="#fndef:zhangtwo" class=fnref >[12]</a></sup><sup id="fnref:morawetz"><a href="#fndef:morawetz" class=fnref >[13]</a></sup>, when where considered scenarios when standard pipelines whould have struggled.</p> <p><code>Effort.jl</code> is part of a broader vision to improve cosmological emulators by combining speed, accessibility, and adaptability. Whether youâ€™re exploring the intricacies of galaxy clustering or aiming for cutting-edge inference, <code>Effort.jl</code> promises to be a powerful tool in your arsenal.</p> <p>Furthermore, <code>Effort.jl</code> is written, <em>Ã§a va sans dire</em>, in pure <code>Julia</code>. This means that it can be easily deployed on different kind of machines, even on Android smartphones. Yes, I have used <code>Effort.jl</code> on my Android smartphone and it was incredibly performant also there<sup id="fnref:girlfriend"><a href="#fndef:girlfriend" class=fnref >[14]</a></sup>.</p> <p>Let us now give a quick summary of the main selling points of the <code>Effort.jl</code> emulator.</p> <div class=franklin-toc ><ol><li><a href="#installation_usage">Installation &amp; Usage</a><li><a href="#precision_tests_residual_curves_chains">Precision tests: residual curves &amp; chains</a><li><a href="#ok_and_now">Ok, and now?</a></ol></div> <h2 id=installation_usage ><a href="#installation_usage" class=header-anchor >Installation &amp; Usage</a></h2> <p>Installing <code>Effort.jl</code> is quite easy. After moving to the package environment, you can enter the Pkg REPL by pressing <code>&#93;</code> from the Julia REPL. To get back to the Julia REPL, press <code>Ctrl&#43;C</code> or backspace &#40;when the REPL cursor is at the beginning of the input&#41;.</p> <p>Upon entering the Pkg REPL, you should see the following prompt:</p> <pre><code class="julia hljs">(<span class=hljs-meta >@v1</span><span class=hljs-number >.11</span>) pkg&gt;</code></pre>
<p>Now you can install <code>Effort.jl</code></p>
<pre><code class="julia hljs">(<span class=hljs-meta >@v1</span><span class=hljs-number >.11</span>) pkg&gt; add https://github.com/CosmologicalEmulators/Effort.jl</code></pre>
<p>Now load the following packages</p>
<pre><code class="julia hljs"><span class=hljs-keyword >using</span> Effort</code></pre>
<p>Now you have to load the trained emulator. Assuming the trained emulator is in a specific folder,</p>
<pre><code class="julia hljs">emu = Effort.load_multipole_emulator(<span class=hljs-string >&quot;/path/to/folder&quot;</span>)</code></pre>
<p>Easy, isn&#39;t it?</p>
<p>We can now use the loaded emulator to compute some <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>P</mi><mi mathvariant=normal >â„“</mi></msub><mo stretchy=false >(</mo><mi>k</mi><mo stretchy=false >)</mo></mrow><annotation encoding="application/x-tex">P_\ell(k)</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class=mord ><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">â„“</span></span></span></span><span class=vlist-s >â€‹</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span><span class=mopen >(</span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class=mclose >)</span></span></span></span>&#39;s&#33; In order to do that you need to pass the input cosmological parameters as a vector <code>input_test</code>, the growth factor <code>D</code> &#40;more on this later&#41;, and the biases <code>biases</code>.</p>
<pre><code class="julia hljs">Effort.get_Pâ„“(input_test, D, biases, emu)</code></pre>
<p>That&#39;s it&#33; The mean execution time of <code>Effort.jl</code> is of <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>15</mn><mtext>â€‰</mtext><mi>Î¼</mi><mi>s</mi></mrow><annotation encoding="application/x-tex">15\,\mu s</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.8389em;vertical-align:-0.1944em;"></span><span class=mord >15</span><span class=mspace  style="margin-right:0.1667em;"></span><span class="mord mathnormal">Î¼</span><span class="mord mathnormal">s</span></span></span></span>&#33;</p>
<h2 id=precision_tests_residual_curves_chains ><a href="#precision_tests_residual_curves_chains" class=header-anchor >Precision tests: residual curves &amp; chains</a></h2>
<p><code>Effort.jl</code> is the fastest EFTofLSS emulator available. But is it precise?</p>
<p>Let us start plotting the distribution of the percentage residuals. We are doing this for 4 different scenarios, in order to gauge the impact of the preprocessing and the training dataset size. Specifically, the 11 and counterterms contributions are linear in <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>P</mi><mrow><mi mathvariant=normal >l</mi><mi mathvariant=normal >i</mi><mi mathvariant=normal >n</mi></mrow></msub></mrow><annotation encoding="application/x-tex">P_\mathrm{lin}</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.8333em;vertical-align:-0.15em;"></span><span class=mord ><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathrm mtight">lin</span></span></span></span></span><span class=vlist-s >â€‹</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> while the loop term is quadratic in <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>P</mi><mrow><mi mathvariant=normal >l</mi><mi mathvariant=normal >i</mi><mi mathvariant=normal >n</mi></mrow></msub></mrow><annotation encoding="application/x-tex">P_\mathrm{lin}</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.8333em;vertical-align:-0.15em;"></span><span class=mord ><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathrm mtight">lin</span></span></span></span></span><span class=vlist-s >â€‹</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> &#40;up to IR contributions&#41;. We the decided to train the emulators by rescaling the output of <code>pybird</code> by a factor that accounts for the linear rescaling of the <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>P</mi><mrow><mi mathvariant=normal >l</mi><mi mathvariant=normal >i</mi><mi mathvariant=normal >n</mi></mrow></msub></mrow><annotation encoding="application/x-tex">P_\mathrm{lin}</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.8333em;vertical-align:-0.15em;"></span><span class=mord ><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathrm mtight">lin</span></span></span></span></span><span class=vlist-s >â€‹</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>. We considered four different approaches:</p>
<ul>
<li><p>No rescaling at all, thestandard baseline.</p>

<li><p>Rescaling by <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>A</mi><mi mathvariant=normal >s</mi></msub></mrow><annotation encoding="application/x-tex">A_\mathrm{s}</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.8333em;vertical-align:-0.15em;"></span><span class=mord ><span class="mord mathnormal">A</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathrm mtight">s</span></span></span></span><span class=vlist-s >â€‹</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>. This takes into account the initial scalar fluctuations amplitude.</p>

<li><p>Rescaling by <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>D</mi><mn>2</mn></msup><mo stretchy=false >(</mo><mi>z</mi><mo stretchy=false >)</mo></mrow><annotation encoding="application/x-tex">D^2(z)</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1.0641em;vertical-align:-0.25em;"></span><span class=mord ><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class=msupsub ><span class=vlist-t ><span class=vlist-r ><span class=vlist  style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class=mopen >(</span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class=mclose >)</span></span></span></span>. This takes into account the redshift evolution as a funciton of cosmological parameters.</p>

<li><p>Rescaling by <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>A</mi><mi mathvariant=normal >s</mi></msub><msup><mi>D</mi><mn>2</mn></msup><mo stretchy=false >(</mo><mi>z</mi><mo stretchy=false >)</mo></mrow><annotation encoding="application/x-tex">A_\mathrm{s} D^2(z)</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1.0641em;vertical-align:-0.25em;"></span><span class=mord ><span class="mord mathnormal">A</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathrm mtight">s</span></span></span></span><span class=vlist-s >â€‹</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span><span class=mord ><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class=msupsub ><span class=vlist-t ><span class=vlist-r ><span class=vlist  style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class=mopen >(</span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class=mclose >)</span></span></span></span>. This takes into account both previous effects.</p>

</ul>
<p>We will gauge the impact of the size of the training dataset, using two datasets, with respectively 20,000 &#40;dashed lines&#41; and 60,000 &#40;solid lines&#41; elements.</p>
<p>Here are the results&#33;</p>
<p><img src="https://private-user-images.githubusercontent.com/58727599/492058747-e0a6ecb5-8a02-4609-8ff6-3cac7cf648ff.png?jwt&#61;eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NTg0ODgyNzgsIm5iZiI6MTc1ODQ4Nzk3OCwicGF0aCI6Ii81ODcyNzU5OS80OTIwNTg3NDctZTBhNmVjYjUtOGEwMi00NjA5LThmZjYtM2NhYzdjZjY0OGZmLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTA5MjElMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwOTIxVDIwNTI1OFomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTQ4NDBiYzUzMTNmNGVkNzIzNTg3NzU5NmI3ZjUwOTY3NDkyYTcxNDBiM2I1NzlhNGVmNTUyNDI5NzU5NWFiNzYmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.l3XLta0qSNL-66HXH2qqHXWnHdxvPBuGLoQdbGsffgs" alt="Effort error distribution" /></p>
<p>As can be seen, the impact of the preprocessing is more important than that of the training dataset size&#33; This means that yes, having a larger dataset can help you getting a better emulator, but leveraging our domain knowledge as scientists is even better&#33;</p>
<p>These are not the only tests we performed in order to assess the accuracy of our emulators. We analyzed the PT-challenge and BOSS datasets.</p>
<p>Here comes one of the <code>Julia</code> strenghts: the high interoperability of its ecosystem. Given our <code>Turing.jl</code> likelihood, we can use different analysis algorithms:</p>
<ul>
<li><p>NUTS, the No-U-Turn-Sampler. This is the state-of-the-art gradient-based sampler</p>

<li><p>MicroCanonical Hamiltonian MonteCarlo, MCHMC, a recently developed Hamiltonian MonteCarlo Sampler</p>

<li><p>Pathfinder, a variational inference algorithm, here used to initialize the chains of the previous methods</p>

</ul>
<p>The <code>Julia</code> implementation of these algorithms is interfaced with <code>Turing.jl</code>, so we can easily test these algorithms with our likelihoods&#33; What is the result of this comparison?</p>
<p><img src="https://github.com/user-attachments/assets/f7df018e-bd37-4e7b-99bd-bbd3e9e86584" alt=contour_comparison_Effort_BOSS  /> The chains are basically the same, with differences of about <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0.1</mn><mi>Ïƒ</mi></mrow><annotation encoding="application/x-tex">0.1\sigma</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.6444em;"></span><span class=mord >0.1</span><span class="mord mathnormal" style="margin-right:0.03588em;">Ïƒ</span></span></span></span>. But what about the computational performance?</p>
<ul>
<li><p><code>pybird</code> analyzed the BOSS dataset with  ~ <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1000</mn></mrow><annotation encoding="application/x-tex">1000</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.6444em;"></span><span class=mord >1000</span></span></span></span> CPUhours, even though it was using analytical marginalization</p>

<li><p><code>Effort.jl</code> &#43; NUTS employed 1 hour of wall-time, with an ESS/s of 0.4</p>

<li><p><code>Effort.jl</code> &#43; MCHMC required less than 1 hour of wall-time, with an ESS/s of 2.4</p>

</ul>
<h2 id=ok_and_now ><a href="#ok_and_now" class=header-anchor >Ok, and now?</a></h2>
<p>Although the <code>Effort.jl</code> release paper has just been accepted on JCAP<a href="and there was even some media coverage about it&#91;^effort-press&#93;&#33;">^effort-paper</a> there are a few things we are working on about:</p>
<ul>
<li><p>A <code>jax</code> compatible version, <code>jaxeffort</code>. This is mostly done, and it is available on <a href="https://github.com/CosmologicalEmulators/jaxeffort">GitHub</a>.</p>

<li><p>Batteries included. I am including by default some emulators into the packages, such that they can be used out-of-the-box.</p>

<li><p>A restructuring. In order to ease certain developments, I am reorganizing a bit the structure of the code &#40;and most likely found a design that satisfies me&#41;.</p>

</ul>
<p>Finally, the other important point: applications&#33; A piece of code is as good as its applications, so here is what we have been doing:</p>
<ul>
<li><p>HOD-Informed Priors &#40;HIP&#41;. With a colleague of mine, Hanyu Zhang, we have been working on a way to enhance the EFTofLSS analyses by placing tighter priors on the EFT parameters. This boils down to get some simulations, populate them with an HOD approach, measure the <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>P</mi><mi mathvariant=normal >â„“</mi></msub></mrow><annotation encoding="application/x-tex">P_\ell</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.8333em;vertical-align:-0.15em;"></span><span class=mord ><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">â„“</span></span></span></span><span class=vlist-s >â€‹</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> and get some bestfits. In these papers of ours&#91;^zhangone, zhangtwo&#93;, this has been done for hundreds of thousands of simulations. This is where the speed and differentiability of the code really shine: the L-BFGS minimization algorithm was employed in these analyses and it proved extremely powerful.</p>

<li><p>Orthogonalization approach to Projection effects. With another colleague of mine, Simone Paradiso, we have been working on a way to reduce the Projection effects by reparameterizing the EFT parameters. In such a manner we can reduce the projection effects that are plaguing this kind of analysis.</p>

<li><p>Frequentist analysis. As for the HIP approach, this boils down to computing a lot of bestfits. Also in this case, the differentiability of the code helps like a lot: L-BFGS is a beast of an algorithm, and it can easily handle the large number parameters to adjust during the minimization. A paper on this topic<sup id="fnref:morawetz"><a href="#fndef:morawetz" class=fnref >[13]</a></sup> by my student, James Morawetz, has just been submitted to JCAP.</p>

</ul>
<p>Please, feel free to use the comments-tab here or to drop to me, or any of my colleagues, an email for questions or comments.</p>
<p><table class=fndef  id="fndef:classnet">
    <tr>
        <td class=fndef-backref ><a href="#fnref:classnet">[1]</a>
        <td class=fndef-content ><a href="https://arxiv.org/abs/2207.05707">CosmicNet II: Emulating extended cosmologies with efficient and accurate neural networks &#40;2022&#41;</a>
    
</table>
<table class=fndef  id="fndef:cosmopower">
    <tr>
        <td class=fndef-backref ><a href="#fnref:cosmopower">[2]</a>
        <td class=fndef-content ><a href="https://arxiv.org/abs/2106.03846">COSMOPOWER: emulating cosmological power spectra for accelerated Bayesian inference from next-generation surveys</a>
    
</table>
<table class=fndef  id="fndef:emulatelss">
    <tr>
        <td class=fndef-backref ><a href="#fnref:emulatelss">[3]</a>
        <td class=fndef-content ><a href="https://arxiv.org/abs/2112.05889">Neural network acceleration of large-scale structure theory calculations</a>
    
</table>
<table class=fndef  id="fndef:matryoshka">
    <tr>
        <td class=fndef-backref ><a href="#fnref:matryoshka">[4]</a>
        <td class=fndef-content ><a href="https://arxiv.org/abs/2202.07557">matryoshka II: accelerating effective field  theory analyses of the galaxy power spectrum</a>
    
</table>
<table class=fndef  id="fndef:comet">
    <tr>
        <td class=fndef-backref ><a href="#fnref:comet">[5]</a>
        <td class=fndef-content ><a href="https://arxiv.org/abs/2208.01070">Clustering observables modelled by emulated perturbation theory</a>
    
</table>
<table class=fndef  id="fndef:cobra">
    <tr>
        <td class=fndef-backref ><a href="#fnref:cobra">[6]</a>
        <td class=fndef-content ><a href="https://arxiv.org/abs/2407.04660">COBRA: Optimal Factorization of Cosmological Observables</a>
    
</table>
<table class=fndef  id="fndef:zhangone">
    <tr>
        <td class=fndef-backref ><a href="#fnref:zhangone">[9]</a>
        <td class=fndef-content ><a href="https://arxiv.org/abs/2409.12937">HOD-informed prior for EFT-based full-shape analyses of LSS</a>
    
</table>
<table class=fndef  id="fndef:paradiso">
    <tr>
        <td class=fndef-backref ><a href="#fnref:paradiso">[10]</a>
        <td class=fndef-content ><a href="https://arxiv.org/abs/2412.03503">Reducing nuisance prior sensitivity via non-linear reparameterization, with application to EFT analyses of large-scale structure</a>
    
</table>
<table class=fndef  id="fndef:baleato">
    <tr>
        <td class=fndef-backref ><a href="#fnref:baleato">[11]</a>
        <td class=fndef-content ><a href="https://arxiv.org/abs/2501.10587">Selecting samples of galaxies with fewer Fingers-of-God</a>
    
</table>
<table class=fndef  id="fndef:zhangtwo">
    <tr>
        <td class=fndef-backref ><a href="#fnref:zhangtwo">[12]</a>
        <td class=fndef-content ><a href="https://arxiv.org/abs/2504.10407">Enhancing DESI DR1 Full-Shape analyses using HOD-informed priors</a>
    
</table>
<table class=fndef  id="fndef:morawetz">
    <tr>
        <td class=fndef-backref ><a href="#fnref:morawetz">[13]</a>
        <td class=fndef-content ><a href="https://arxiv.org/abs/2508.11811">Frequentist Cosmological Constraints from Full-Shape Clustering Measurements in DESI DR1</a>
    
</table>
<table class=fndef  id="fndef:pun">
    <tr>
        <td class=fndef-backref ><a href="#fnref:pun">[8]</a>
        <td class=fndef-content >Pun <em>totally</em> intended.
    
</table>
<table class=fndef  id="fndef:girlfriend">
    <tr>
        <td class=fndef-backref ><a href="#fnref:girlfriend">[14]</a>
        <td class=fndef-content >When I told this to my girlfriend her honest reaction was &quot;Are you trying to get single again?&quot;.
    
</table>
&#91;^effort-paper&#93; <a href="https://iopscience.iop.org/article/10.1088/1475-7516/2025/09/044">Effort.jl: a fast and differentiable emulator for the Effective Field Theory of the Large Scale Structure of the Universe</a> &#91;^effort-press&#93; <a href="https://www.sciencedaily.com/releases/2025/09/250918225001.html">Cosmic simulations that once needed supercomputers now run on a laptop</a>       <script src="https://utteranc.es/client.js" repo="marcobonici/marcobonici.github.io"
              issue-term=url  label=comments  theme=github-light  crossorigin=anonymous 
              async>
      </script>
</p>
<!-- <div class=page-foot >
    <a href="http://creativecommons.org/licenses/by-sa/4.0/">CC BY-SA 4.0</a> {{ fill author }}. {{isnotpage /tag/*}}Last modified: {{ fill fd_mtime }}.{{end}}
    Website built with <a href="https://github.com/tlienart/Franklin.jl">Franklin.jl</a> and the <a href="https://julialang.org">Julia programming language</a>.
</div> -->
</div>

      </div> 
    </div>   

    <div class=page__footer >
      <footer>
        
        
        <div class=page__footer-follow >
          <ul class=social-icons >
            <li><strong>Follow:</strong>
            <li><a href="https://twitter.com/marcobonici" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-twitter-square" aria-hidden=true ></i> Twitter</a>
            <li><a href="https://mathstodon.xyz/@marcobonici" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-mastodon" aria-hidden=true ></i> Mastodon</a>
            <li><a href="https://github.com/marcobonici" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-github" aria-hidden=true ></i> GitHub</a>
          </ul>
        </div>
        <div class=page__footer-copyright >&copy; Marco Bonici. Powered by <a href="https://github.com/tlienart/Franklin.jl">Franklin.jl</a>,  <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel=nofollow >Minimal Mistakes</a>
          and the <a href="https://julialang.org">Julia programming language</a>.</div>
      </footer>
    </div>

    <script src="/libs/minimal-mistakes/main.min.js"></script>
    <script defer src="https://use.fontawesome.com/releases/v5.8.2/js/all.js" integrity="sha384-DJ25uNYET2XCl5ZF++U8eNxPWqcKohUUBUpKGlNLMchM7q4Wjg2CUpjHLaL8yYPH" crossorigin=anonymous ></script>

    
        



    
    
        


    
  




<script>
  (function(){

    // Get the elements.
    // - the 'pre' element.
    // - the 'div' with the 'paste-content' id.

    var pre = document.getElementsByTagName('pre');

    // Add a copy button in the 'pre' element.
    // which only has the className of 'language-' or ' hljs'(if enable highlight.js pre-render).

    for (var i = 0; i < pre.length; i++) {
      var tag_name = pre[i].children[0].className
                var isLanguage = tag_name.startsWith('language-') || tag_name.endsWith(' hljs');
      if ( isLanguage ) {
        var button           = document.createElement('button');
            button.className = 'copy-button';
            button.textContent = 'Copy';

            pre[i].appendChild(button);
      }
    };

    // Run Clipboard

    var copyCode = new Clipboard('.copy-button', {
      target: function(trigger) {
        return trigger.previousElementSibling;
      }
    });

    // On success:
    // - Change the "Copy" text to "Copied".
    // - Swap it to "Copy" in 2s.
    // - Lead user to the "contenteditable" area with Velocity scroll.

    copyCode.on('success', function(event) {
      event.clearSelection();
      event.trigger.textContent = 'Copied';
      window.setTimeout(function() {
        event.trigger.textContent = 'Copy';
      }, 2000);

    });

    // On error (Safari):
    // - Change the  "Press Ctrl+C to copy"
    // - Swap it to "Copy" in 2s.

    copyCode.on('error', function(event) {
      event.trigger.textContent = 'Press "Ctrl + C" to copy';
      window.setTimeout(function() {
        event.trigger.textContent = 'Copy';
      }, 5000);
    });

  })();
  </script>